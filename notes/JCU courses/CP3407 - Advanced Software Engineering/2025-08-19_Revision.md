---
date: "2025-08-19"
location: 
    - JCU courses/CP3407 - Advanced Software Engineering
hubs: 
    - "[[]]"
urls:
    - 
---

# Revision

## Week 1
+ Deliver software that’s needed
+ Deliver software on time
+ Deliver software on budget

## Week 2
User stories should
+ Describe one thing that software needs to do for customer
+ Written in a language that the customer understands
+ Written by the customer
+ Be short - no more than 3 sentences
User stories should not
+ Be long essay
+ Use technical terms that's unfamiliar
+ Mention specific technologies

## Week 3
**DO**
+ Balance functionality with customer impatience 
**DON't**
+ Get caught planning nice-to-haves
+ Worry about length (yet)

**To reprioritize**
1. Cut more functionality
2. Ship a milestone build as early as possible
3. Focus on baseline functionality

**Bullshit**
Iterations are building blocks while milestones are checkpoints that mark the progress of the project as a whole

### Burn down rate graph
This graph monitors how quickly you and your team are completing your work, measured in days on the vertical axis. This chart then plots how quickly you tick off your work remaining against the number of days left in your iteration
    
## Week 4
+ Track progress
+ Update burn-down rate
+ Update tasks
+ Talk about what happened yesterday / What will happen today
+ Bring up any issues
+ Last between 5 and 15 minutes

It’s not only difficult to stay focused on a long task, but you will be more confident estimating the work involved the shorter the task is.

** TODO **: Do scrum week 4

Unpllned task is still a task - treat it like the others

# Week 5
+ Deliver on time
+ Get paid for the sufficient work you do
+ Save time

## Week 7
**Black box testing**
+ Functionality
+ User input validation 
+ Output results
+ State transitions
+ Boundary cases and off-by-one errors

**Grey box testing**
+ Verififying auditing and logging
+ Data destined for other systems
+ System-added info
+ Scraps left lying around

**White box testing**
+ Digging into the code to find errors
+ Testing all branches of the code

+ Detecting when new chane introduce bug to older code, called software regression => Need to run all tests to check
+ Aim for 85%-90% test coverage
+ Code coverage is a much better metric of testing effectiveness than test count

## Week 8
1. Red: Your test fails. First you write a test that checks whatever functionality you’re about to write. Obviously it fails, since you haven’t implemented the functionality yet. This is the red stage, since your test GUI probably shows the test in red (failing).
2. Green: Your test passes. Next, implement the functionality to get that test to pass. That’s it. No more. Nothing fancy. Write the simplest code you can to get your test to pass. This is the green stage.
3. Refactor: Clean up any duplication, ugliness, old code, etc. Finally, after your test passes, you can go back in and clean up some things that you may have noticed while implementing your code. This is the refactor stage

+ Test-driven dev is about creating tests for specific functionalities and then write code to satisfy that functionality (anything beyond is not important - for now)

+ Strategy pattern provides for multiple implementations of a single innterface
+ Simplicity means avoid dependency - dependencies make it hard to test

**Benefits**
+ Well organized code (production - test)
+ Code that always does the same thing 
+ Loosely coupled code - make it more flexible

+ Lowly coupling: classes depend on abstraction -> change implementations without ripple effects
+ High cohension: classes focus on one logical area (db, business, etc) -> clear separation of concerns 

+ More tests always means lots more code
+ Automated test-driven dev means LOT of test code

+ Mock object - stands in for real objects
+ The mock framework will handle creating implementations of the interface and keeping track of what methods we say should be called, what they should return when they are called, what shouldn’t be called, etc. The mock framework’s implementation of our interface will track all of this and throw an error if something doesn’t go according to the plan we gave it
=> A good mock object framework allows you to simulate an object's behaviour, without writing code for that object

+ Keep your tests in a parallel structure to your source code, such as in a tests/ directory. Most build and automated testing tools play nicely with that setup

+ Good code coverage is easier in TDD

## Week 9
+ System testing exercises the FUNCTIONALITY of the system from front to back in real-world, black-box scenarios.
+ Good system testing requires TWO iteration cycles
+ The key to most problems you’ll run into in software development is COMMUNICATION. When in doubt, TALK to your team, other teams, and your customer

### Life and death of a bug
+ Tester finds bug
+ Tester files a bug report
+ Create a story (task) to fix the bug
+ Fix the byg
+ Check the fix and verify it work 
+ Update bug report

+ Bugs belong in bug tracker
+ Rexord + Communicate priorities
+ Keep track of everything
+ Generate metrics (zero-bug-bounce->all outstanding bugs are fixed)

### Anatomy of a bug report
+ Summary
+ Steps to produce
+ What you expected to happen vs what really happened
+ Version / Platform / Location information
+ Severity / Priority

### Iteration reviews
1. Prepare ahead
2. Be forward-looking
3. Calculte metrics
4. Have standard set of questions to review

## Week 10
1. Mock objects give you a way to create custom implementations of interfaces without needing to actually write the code
2. The mock framework will handle creating implementations of the interface and keeping track of what methods we say should be called, what they should return when they are called, what shouldn’t be called, etc and return if any of the above is not satisfied
